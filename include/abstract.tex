
This {dissertation} explores advanced optimization techniques, focusing on hyperparameter tuning, design strategy selection, and novel optimization methods. First, we investigate a modified Differential Evolution (DE) algorithm for generating {uniform projection designs}, emphasizing the importance of hyperparameter configuration. We analyze the surface structure of these hyperparameters and provide guidelines for optimizing settings under various conditions. Next, we examine the role of initial design choices in prediction and sequential optimization using Efficient Global Optimization (EGO), demonstrating that uniform projection designs outperform traditional strategies such as maximin distance designs, particularly in high-dimensional spaces. Finally, we introduce a Kriging-based sequential region shrinking method that integrates EGO to efficiently reduce the search space by targeting promising data points. Comparative results show that this method {not only} requires fewer computational resources than conventional tuning techniques like grid and random search, {but also} outperforms other Bayesian optimization methods such as TREGO. These findings offer significant contributions to the optimization field, enhancing both theoretical understanding and practical applications.




% We present a comprehensive study of advanced optimization techniques, with a focus on hyperparameter tuning, initial design strategies, and the development of innovative optimization methods. First, we investigate the modified Differential Evolution (DE) algorithm, which has been adapted for generating optimal Uniform Projection Designs in discrete data spaces. By analyzing the surface structure of key hyperparameters, we uncover their relative contributions to the algorithm's performance and provide detailed guidelines for selecting optimal hyperparameter configurations across different problem setups. This analysis highlights the need for careful hyperparameter tuning in order to achieve robust and efficient design generation.

% Next, we explore the impact of initial design choices in the context of sequential optimization, using the Efficient Global Optimization (EGO) algorithm. Employing Gaussian Processes to model diverse data sets, and Active Learning to efficiently select data points, we demonstrate how early-stage design choices significantly influence optimization performance. Through a comparative study, we find that distance-based designs, such as Maximin, underperform in high-dimensional spaces, while Uniform Projection Designs, particularly those optimized using the centered L2-discrepancy criterion, consistently deliver superior results. These findings underscore the importance of selecting effective initial design strategies, especially when dealing with high-dimensional optimization tasks.

% Building on these insights, we introduce a novel Kriging-based sequential region shrinking method that integrates the EGO algorithm. This method progressively reduces the region of interest by concentrating on the most promising data points, thus optimizing the search process more efficiently. Through extensive testing on well-known physical test functions, we demonstrate that this approach significantly reduces computational costs compared to traditional hyperparameter tuning techniques, such as grid search and random search. Furthermore, it shows an edge over other Bayesian optimization methods, including the TREGO algorithm, in terms of both resource efficiency and optimization accuracy.

% Overall, this study offers substantial contributions to the field of optimization by advancing our understanding of hyperparameter tuning in modified DE algorithms, improving initial design selection for high-dimensional problems, and proposing a resource-efficient, Kriging-based sequential region shrinking method. The findings are applicable to a wide range of optimization problems, from theoretical research to practical applications, providing new insights and methodologies for solving complex optimization challenges.
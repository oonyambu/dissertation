
\chapter{Introduction}

\noindent



Optimization algorithms play a crucial role in addressing complex real-world problems, where identifying optimal solutions requires efficient navigation of large, often high-dimensional search spaces. Various metaheuristic algorithms, such as Particle Swarm Optimization (PSO), Simulated Annealing (SA), Threshold Acceptance (TA), Genetic Algorithms (GA) and Differential Evolution (DE), provide the tools needed to find solutions across a variety of domains, from engineering to scientific research. Among these methods, Differential Evolution (DE) has emerged as a popular choice for continuous optimization, thanks to its simplistic nature, strong global search capabilities, robust performance and flexibility in a range of applications \parencite{storn1997differential}. In addition, DE has high convergence speed for certain problems \parencite{babu2003differential} and is parallelizable \parencite{kukkonen2006constrained}.

However, using Differential Evolution for discrete data tasks, such as experimental design generation, presents challenges. Applying DE in such cases requires modifications to its foundational structure to effectively manage discrete variables. Recent work by \textcite{stokes2023metaheuristic} introduced a modified DE algorithm specifically tailored for these discrete tasks, highlighting the need for adaptations to extend DE's functionality beyond continuous domains. Despite these advancements, the algorithm's performance remains highly sensitive to several hyperparameters, which play a critical role in influencing outcomes.

This sensitivity to hyperparameters emphasizes the importance of understanding and exploring the hyperparameter landscape. Developing optimized settings across different problem setups is essential for achieving reliable and efficient performance. Tailoring hyperparameters for specific tasks or datasets can greatly improve outcomes, but doing so requires a structured approach to hyperparameter tuning. As such, there is a need for strategies that systematically optimize hyperparameter configurations to align with varied and complex problem requirements. 

In addition, Bayesian optimization has become a widely adopted approach for black-box optimization problems, particularly for its sequential nature in handling noisy and non-convex functions commonly encountered in real-world scenarios. The framework often relies on Efficient Global Optimization (EGO), a sequential strategy that iteratively searches for optimal solutions by balancing exploration of the search space and exploitation of known high-performing regions \parencite{jones1998efficient}. At each step, Bayesian optimization evaluates new points based on their potential to improve the objective function while accounting for the uncertainty of the model predictions. This iterative, or sequential, nature allows Bayesian optimization to progressively refine its estimates, focusing on promising regions and thereby enhancing efficiency.

In Bayesian optimization, a Gaussian Process (GP) is typically used as the surrogate model, offering a flexible and powerful approach for modeling complex functions \parencite{rasmussen2006gaussian}. GPs are particularly valuable because they predict the objective function's value at unexplored points and provide an estimate of prediction uncertainty, which can guide decisions on where to sample next. The choice of acquisition function, also known as the utility function, is central to Bayesian optimization, as it defines the criteria for selecting the next sample point. Common acquisition functions include Probability of Improvement (PI), Expected Improvement (EI), Upper Confidence Bound (UCB), and Lower Confidence Bound (LCB), each designed to guide the search process differently depending on the optimization strategy.

The Probability of Improvement (PI) function, for instance, favors points likely to outperform the current best-known solution, focusing on regions with high potential for incremental gains. Expected Improvement (EI), on the other hand, seeks points that offer the highest potential for improvement by integrating both the predicted mean and the uncertainty of the GP model, balancing exploration and exploitation more effectively \parencite{mockus1994application}. The Upper Confidence Bound (UCB) and Lower Confidence Bound (LCB) functions apply a degree of confidence to the GP predictions, where UCB emphasizes exploration by targeting areas with high uncertainty, while LCB may be used to address risk-averse or cost-sensitive problems by minimizing potential loss \parencite{srinivas2009gaussian}.

These acquisition functions collectively enable Bayesian optimization to adapt dynamically based on the task requirements. Each function aligns with different optimization objectives, allowing Bayesian optimization to tailor its approach to complex landscapes and focus computational resources on the most promising areas of the search space. This adaptability, coupled with the sequential nature of EGO, makes Bayesian optimization a powerful method for tackling diverse and challenging optimization problems.

In this dissertation, we employ the DE algorithm and a novel localized region shrinkage Bayesian optimization in the construction of the uniform projection designs. Three studies are done and the structure of these studies is laid as follows.

The first study delves into the construction of space-filling designs focusing mainly on Uniform Projection Designs (UPDs) by investigating the surface structure of DE's hyperparameters and their respective contributions. {UPDs, introduced by \textcite{sun2019uniform}, are a special class of space-filling designs} that ensure an even distribution of sample points across all lower-dimensional projections of a high-dimensional design space. By analyzing the impact of hyperparameters on the performance of the modified DE algorithm, the study aims to derive optimal settings for generating {efficient UPDs} using a second-order model. Through comparisons of various experimental designs and surrogate models, the research provides crucial guidelines for enhancing DE's performance. The insights gained from this study are intended to equip practitioners with effective strategies for optimizing hyperparameter configurations in practical applications.

Another critical aspect of optimization algorithms is the initial design choices, which can significantly impact both prediction accuracy and the efficiency of sequential optimization processes. The second study utilizes gaussian process and various initial experimental designs to model test functions determining the prediction power of the initial design. In addition, {the effect of the initial design on the optimization performance via active learning}  is evaluated. This study highlights how initial design strategies greatly influence prediction prowess and early optimization results, with their effects diminishing as iterations proceed toward the global optimum. In particular, the research demonstrates that distance-based designs, like {maximin distance designs}, struggle in high-dimensional settings, whereas Uniform Projection Designs consistently perform well across varying dimensionalities.

In response to the challenges associated with traditional optimization approaches, the third study introduces a novel Kriging-based sequential region shrinking method, which effectively incorporates the EGO algorithm. This innovative method aims to progressively reduce the region of interest by focusing on the most promising data points during each iteration. The efficiency of this approach is validated through its application to various well-known physical test functions, where it significantly reduces the computational resources required compared to traditional hyperparameter tuning techniques like grid and random search. Furthermore, it demonstrates advantages over other Bayesian optimization strategies, such as TREGO, highlighting its practicality in resource-constrained environments.

Together, these studies provide a comprehensive exploration of advanced optimization techniques, ranging from hyperparameter tuning in DE to effective design strategy selection, culminating in novel optimization methods. The findings contribute valuable insights to both theoretical research and practical applications, showcasing the evolving landscape of optimization strategies. By bridging the gaps in existing methodologies, this work aims to enhance the efficacy of optimization processes across diverse fields, ultimately leading to more robust and efficient solutions for complex challenges.


\chapter{Conclusion and Future Directions}

The studies presented in this work advance the understanding and application of optimization methods and experimental design in addressing complex, high-dimensional challenges in design construction. Optimization algorithms, especially Differential Evolution (DE) and Bayesian optimization, have demonstrated their capability to tackle intricate real-world problems requiring efficient navigation of extensive search spaces. This dissertation has focused on three interlinked studies: optimizing DE hyperparameters for constructing Uniform Projection Designs (UPDs), evaluating initial design choices for prediction and optimization, and introducing a Kriging-based sequential shrinkage method for enhancing Bayesian optimization. Collectively, these studies provide essential insights into how the structure and strategy of optimization methods can be tailored to suit varied problem domains, resulting in improved accuracy, efficiency, and scalability.

This chapter synthesizes the findings of these studies, discussing their implications and highlighting directions for future work in advancing optimization techniques.

\section{Key Findings Across the Studies}

\subsection{Optimizing Hyperparameters in Differential Evolution for UPD Generation}
The first study explored the hyperparameter landscape of a modified DE algorithm applied to discrete tasks, such as generating Uniform Projection Designs (UPDs). DE is traditionally effective for continuous optimization, but modifications to its structure are necessary to handle discrete variables. Inspired by recent work on DE adaptations, this study focused on five critical DE hyperparameters, including population size, maximum iterations, and probabilities related to mutation, crossover and use of the global best. Through extensive testing, OACD and CCD emerged as the most effective experimental designs for exploring DE's hyperparameter response surface, outperforming space-filling designs in terms of root mean squared error and correlation with the underlying objective.

This analysis, built upon second-order model as the surrogate model, revealed that second-order models offer a reliable yet simpler alternative to more complex surrogate approaches, such as Kriging and heteroskedastic Gaussian Processes (GPs). This is significant because identifying optimal hyperparameter settings is not only crucial for enhancing DE's performance but also for constructing high-quality UPDs, which have applications in a variety of fields that require uniformity across high-dimensional spaces. The study highlights the importance of structured hyperparameter tuning in optimizing DE's utility, establishing OACD and CCD as powerful tools for practitioners seeking to leverage DE in discrete optimization contexts.

\subsection{Efficiency and Robustness of UPDs in High-Dimensional Prediction and Optimization Tasks}
The second study assessed the effectiveness of various initial design strategies within the framework of prediction and optimization. By using Gaussian Process (GP) models as surrogate and focusing on active learning through selective sampling, this study highlighted the influence of initial design on prediction accuracy and optimization efficiency. In particular, Uniform Projection Designs (UPDs) consistently outperformed distance-based designs, such as maximin and MaxPro designs, especially in high-dimensional spaces. This advantage is attributed to the UPD's focus on two-dimensional uniformity via the centered \(L_2\)-discrepancy criterion, which circumvents the inefficiencies associated with Euclidean distance metrics in high-dimensional contexts and curse of dimensionality.

The performance of UPDs highlights the limitations of distance-based designs in high dimensions. Euclidean-based metrics, such as those used in maximin designs, tend to falter in high-dimensional settings where points become uniformly distant from one another. In contrast, UPDs maintain efficiency by avoiding reliance on high-dimensional distances, instead leveraging two-dimensional uniformity, which ensures more consistent prediction accuracy across varying dimensionalities. This study's findings underscore the importance of initial design choice in prediction and also in optimization via EGO processes, particularly when early-stage optimization has a pronounced impact on convergence and overall accuracy.

\subsection{Introducing a Sequential Shrinking Approach to Bayesian Optimization for Resource-Efficient Tuning}
The third study introduced a Kriging-based sequential region shrinking method, enhancing traditional Bayesian optimization techniques by focusing on progressively smaller, more promising regions in the search space. This novel approach incorporates aspects of EGO by iteratively narrowing the search region, allowing the optimization process to converge more efficiently. By targeting high-potential areas in each iteration, the approach significantly reduces the computational resources required compared to traditional grid and random search methods.

The sequential shrinking method not only performs effectively across various test functions but also demonstrates advantages over existing Bayesian strategies, such as TREGO. This is particularly important in resource-constrained scenarios, where reducing computational load without sacrificing optimization quality is paramount. The method's integration of Kriging with a focused region-based approach makes it a practical choice for applications in high-dimensional spaces, where traditional optimization strategies may become computationally prohibitive. As such, this study's findings contribute to a growing body of work emphasizing the role of adaptive, resource-efficient techniques in optimization.

\section{Implications for Optimization Strategies and Practical Applications}

This dissertation's findings emphasize the role of both design selection and adaptive optimization strategies in achieving high performance in complex, high-dimensional tasks. The successful use of UPDs as initial designs in EGO demonstrates that high-dimensional optimization can be more effectively approached by leveraging two-dimensional uniformity rather than high-dimensional Euclidean distances. This insight is essential for practitioners in fields where high-dimensional optimization is necessary, offering a robust alternative to conventional designs that suffer in high-dimensional spaces.

Moreover, the effectiveness of structured search techniques, particularly the novel Kriging-based sequential region shrinking method, highlights the potential of region-focused optimization in resource-constrained applications. By progressively shrinking the search region, this method achieves convergence with reduced computational requirements, which has practical implications for industries where efficiency and speed are critical. Similarly, the use of OACD and CCD in hyperparameter tuning underscores the continued relevance of classical factorial composite designs and the  response surface methodologies, particularly when dealing with highly sensitive or discrete parameters in algorithms like DE.

For practitioners, these studies provide practical insights into choosing appropriate design and search techniques based on problem dimensionality, optimization objectives, and computational constraints. The findings also underscore the value of adaptive frameworks in both design and search, offering a balance between exploration and exploitation that improves optimization outcomes.

\section{Limitations and Future Directions}

Despite the strengths of the findings, this research also identifies limitations that warrant further investigation. First, while the current studies provide evidence for the effectiveness of UPDs in high-dimensional optimization, additional work is needed to explore the theoretical underpinnings of UPDs' performance.The impact of factor interactions in the DE algorithm remains an area for future exploration, particularly in developing more nuanced models that account for interaction effects without introducing excessive model complexity.

Additionally, the sequential shrinking approach, while efficient, could benefit from integration with TREGO or with other advanced machine learning models or ensemble methods, potentially enhancing its adaptability and performance in even more complex search spaces. For instance, exploring hybrid approaches that combine GP models with UPD-based designs or integrating deep learning models for dynamic surrogate modeling may further improve accuracy and computational efficiency.

Furthermore, the Kriging-based shrinking approach and DE hyperparameter optimization would benefit from more comprehensive evaluations across different domains. Future work might explore alternative acquisition functions that enhance adaptability in Bayesian optimization, especially for applications requiring specific trade-offs between exploration and exploitation. Extending these techniques to larger datasets or real-world applications would also validate their utility in practical settings, where high dimensionality and computational costs pose ongoing challenges.

Finally, this research although focuses exclusively on the construction of Uniform Projection Designs (UPDs), it is generalizable to the construction of various space filling designs.  We considered the UPD as there is no established construction methods that currently exist. In future studies, however, we can apply the proposed procedures to construct other space filling desings such as maxPro designs or uniform designs and then compare these with existing designs to assess the efficiency of the proposed methods.

\section{Final Remarks}

In conclusion, this work advances the field of high-dimensional optimization by evaluating and enhancing design and optimization strategies for hyperparameter tuning, experimental design generation, and adaptive region-focused optimization. The findings from the three studies provide a cohesive framework that balances theoretical insights with practical applicability, ultimately paving the way for more robust and efficient optimization techniques. This research not only enhances our understanding of the design and optimization landscape but also contributes valuable tools for tackling complex challenges across scientific, engineering, and industrial applications. The evolving methodologies and insights presented here have significant potential to guide future innovations, leading to more accurate, scalable, and resource-efficient solutions for a wide array of optimization problems.

\pagebreak
